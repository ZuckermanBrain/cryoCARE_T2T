{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train cryo-CARE Network\n",
    "\n",
    "In this notebook we initialize a new model and train it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from train_cryo_care import CryoCARE\n",
    "from csbdeep.models import Config\n",
    "from csbdeep.utils import plot_history\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Model\n",
    "\n",
    "We use the standard `CSBDeep` config."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'axes': 'ZYXC',\n",
       " 'n_channel_in': 1,\n",
       " 'n_channel_out': 1,\n",
       " 'n_dim': 3,\n",
       " 'probabilistic': False,\n",
       " 'train_batch_size': 16,\n",
       " 'train_checkpoint': 'weights_best.h5',\n",
       " 'train_checkpoint_epoch': 'weights_now.h5',\n",
       " 'train_checkpoint_last': 'weights_last.h5',\n",
       " 'train_epochs': 200,\n",
       " 'train_learning_rate': 0.0004,\n",
       " 'train_loss': 'mse',\n",
       " 'train_reduce_lr': {'factor': 0.5, 'min_delta': 0, 'patience': 10},\n",
       " 'train_steps_per_epoch': 75,\n",
       " 'train_tensorboard': True,\n",
       " 'unet_input_shape': (None, None, None, 1),\n",
       " 'unet_kern_size': 3,\n",
       " 'unet_last_activation': 'linear',\n",
       " 'unet_n_depth': 2,\n",
       " 'unet_n_first': 32,\n",
       " 'unet_residual': True}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We set the 'train_steps_per_epoch' to 75. This way \n",
    "# 'train_steps_per_epoch' * 'train_batch_size' = 'num_train_volumes'\n",
    "# 75 * 16 = 1200\n",
    "conf = Config(axes='ZYX', train_loss='mse', train_epochs=200, train_steps_per_epoch=75)\n",
    "vars(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The `CryoCARE` model has a data-augmentation built in, which rotates the patches randomly by 90 degrees\n",
    "# about the Y-Axis\n",
    "model = CryoCARE(conf, 'Tomo110_model', basedir='/data/Tomo110/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Train/Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('/data/Tomo110/train_data/train_data.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data['X']\n",
    "Y = data['Y']\n",
    "X_val = data['X_val']\n",
    "Y_val = data['Y_val']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "75/75 [==============================] - 87s 1s/step - loss: 1.1180 - mse: 1.1180 - mae: 0.8345 - val_loss: 0.8737 - val_mse: 0.8737 - val_mae: 0.7435\n",
      "Epoch 2/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9741 - mse: 0.9741 - mae: 0.7822 - val_loss: 0.8507 - val_mse: 0.8507 - val_mae: 0.7338\n",
      "Epoch 3/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9626 - mse: 0.9626 - mae: 0.7778 - val_loss: 0.8456 - val_mse: 0.8456 - val_mae: 0.7317\n",
      "Epoch 4/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9535 - mse: 0.9535 - mae: 0.7742 - val_loss: 0.8400 - val_mse: 0.8400 - val_mae: 0.7294\n",
      "Epoch 5/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9484 - mse: 0.9484 - mae: 0.7722 - val_loss: 0.8352 - val_mse: 0.8352 - val_mae: 0.7275\n",
      "Epoch 6/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9465 - mse: 0.9465 - mae: 0.7715 - val_loss: 0.8359 - val_mse: 0.8359 - val_mae: 0.7278\n",
      "Epoch 7/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9465 - mse: 0.9465 - mae: 0.7714 - val_loss: 0.8308 - val_mse: 0.8308 - val_mae: 0.7256\n",
      "Epoch 8/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9437 - mse: 0.9437 - mae: 0.7703 - val_loss: 0.8305 - val_mse: 0.8305 - val_mae: 0.7255\n",
      "Epoch 9/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9433 - mse: 0.9433 - mae: 0.7701 - val_loss: 0.8295 - val_mse: 0.8295 - val_mae: 0.7250\n",
      "Epoch 10/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9433 - mse: 0.9433 - mae: 0.7701 - val_loss: 0.8301 - val_mse: 0.8301 - val_mae: 0.7253\n",
      "Epoch 11/200\n",
      "75/75 [==============================] - 79s 1s/step - loss: 0.9422 - mse: 0.9422 - mae: 0.7697 - val_loss: 0.8276 - val_mse: 0.8276 - val_mae: 0.7242\n",
      "Epoch 12/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9413 - mse: 0.9413 - mae: 0.7693 - val_loss: 0.8274 - val_mse: 0.8274 - val_mae: 0.7241\n",
      "Epoch 13/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9412 - mse: 0.9412 - mae: 0.7692 - val_loss: 0.8272 - val_mse: 0.8272 - val_mae: 0.7240\n",
      "Epoch 14/200\n",
      "75/75 [==============================] - 79s 1s/step - loss: 0.9408 - mse: 0.9408 - mae: 0.7691 - val_loss: 0.8272 - val_mse: 0.8272 - val_mae: 0.7241\n",
      "Epoch 15/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9403 - mse: 0.9403 - mae: 0.7689 - val_loss: 0.8268 - val_mse: 0.8268 - val_mae: 0.7238\n",
      "Epoch 16/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9406 - mse: 0.9406 - mae: 0.7690 - val_loss: 0.8255 - val_mse: 0.8255 - val_mae: 0.7233\n",
      "Epoch 17/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9399 - mse: 0.9399 - mae: 0.7687 - val_loss: 0.8260 - val_mse: 0.8260 - val_mae: 0.7235\n",
      "Epoch 18/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9394 - mse: 0.9394 - mae: 0.7685 - val_loss: 0.8250 - val_mse: 0.8250 - val_mae: 0.7231\n",
      "Epoch 19/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9399 - mse: 0.9399 - mae: 0.7687 - val_loss: 0.8246 - val_mse: 0.8246 - val_mae: 0.7229\n",
      "Epoch 20/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9388 - mse: 0.9388 - mae: 0.7682 - val_loss: 0.8244 - val_mse: 0.8244 - val_mae: 0.7228\n",
      "Epoch 21/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9391 - mse: 0.9391 - mae: 0.7683 - val_loss: 0.8237 - val_mse: 0.8237 - val_mae: 0.7225\n",
      "Epoch 22/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9382 - mse: 0.9382 - mae: 0.7680 - val_loss: 0.8240 - val_mse: 0.8240 - val_mae: 0.7226\n",
      "Epoch 23/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9385 - mse: 0.9385 - mae: 0.7681 - val_loss: 0.8234 - val_mse: 0.8234 - val_mae: 0.7223\n",
      "Epoch 24/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9381 - mse: 0.9381 - mae: 0.7680 - val_loss: 0.8232 - val_mse: 0.8232 - val_mae: 0.7223\n",
      "Epoch 25/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9383 - mse: 0.9383 - mae: 0.7680 - val_loss: 0.8246 - val_mse: 0.8246 - val_mae: 0.7229\n",
      "Epoch 26/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9390 - mse: 0.9390 - mae: 0.7683 - val_loss: 0.8226 - val_mse: 0.8226 - val_mae: 0.7220\n",
      "Epoch 27/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9372 - mse: 0.9372 - mae: 0.7676 - val_loss: 0.8226 - val_mse: 0.8226 - val_mae: 0.7220\n",
      "Epoch 28/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9370 - mse: 0.9370 - mae: 0.7675 - val_loss: 0.8228 - val_mse: 0.8228 - val_mae: 0.7221\n",
      "Epoch 29/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9376 - mse: 0.9376 - mae: 0.7677 - val_loss: 0.8232 - val_mse: 0.8232 - val_mae: 0.7223\n",
      "Epoch 30/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9373 - mse: 0.9373 - mae: 0.7676 - val_loss: 0.8216 - val_mse: 0.8216 - val_mae: 0.7216\n",
      "Epoch 31/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9368 - mse: 0.9368 - mae: 0.7674 - val_loss: 0.8217 - val_mse: 0.8217 - val_mae: 0.7216\n",
      "Epoch 32/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9372 - mse: 0.9372 - mae: 0.7675 - val_loss: 0.8222 - val_mse: 0.8222 - val_mae: 0.7218\n",
      "Epoch 33/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9368 - mse: 0.9368 - mae: 0.7674 - val_loss: 0.8219 - val_mse: 0.8219 - val_mae: 0.7217\n",
      "Epoch 34/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9366 - mse: 0.9366 - mae: 0.7673 - val_loss: 0.8218 - val_mse: 0.8218 - val_mae: 0.7216\n",
      "Epoch 35/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9363 - mse: 0.9363 - mae: 0.7672 - val_loss: 0.8209 - val_mse: 0.8209 - val_mae: 0.7213\n",
      "Epoch 36/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9366 - mse: 0.9366 - mae: 0.7673 - val_loss: 0.8219 - val_mse: 0.8219 - val_mae: 0.7217\n",
      "Epoch 37/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9362 - mse: 0.9362 - mae: 0.7671 - val_loss: 0.8205 - val_mse: 0.8205 - val_mae: 0.7211\n",
      "Epoch 38/200\n",
      "75/75 [==============================] - 79s 1s/step - loss: 0.9360 - mse: 0.9360 - mae: 0.7670 - val_loss: 0.8202 - val_mse: 0.8202 - val_mae: 0.7210\n",
      "Epoch 39/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9356 - mse: 0.9356 - mae: 0.7669 - val_loss: 0.8211 - val_mse: 0.8211 - val_mae: 0.7213\n",
      "Epoch 40/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9356 - mse: 0.9356 - mae: 0.7669 - val_loss: 0.8202 - val_mse: 0.8202 - val_mae: 0.7210\n",
      "Epoch 41/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9357 - mse: 0.9357 - mae: 0.7669 - val_loss: 0.8202 - val_mse: 0.8202 - val_mae: 0.7210\n",
      "Epoch 42/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9351 - mse: 0.9351 - mae: 0.7667 - val_loss: 0.8196 - val_mse: 0.8196 - val_mae: 0.7207\n",
      "Epoch 43/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9350 - mse: 0.9350 - mae: 0.7667 - val_loss: 0.8203 - val_mse: 0.8203 - val_mae: 0.7210\n",
      "Epoch 44/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9351 - mse: 0.9351 - mae: 0.7667 - val_loss: 0.8194 - val_mse: 0.8194 - val_mae: 0.7206\n",
      "Epoch 45/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9350 - mse: 0.9350 - mae: 0.7667 - val_loss: 0.8192 - val_mse: 0.8192 - val_mae: 0.7205\n",
      "Epoch 46/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9349 - mse: 0.9349 - mae: 0.7666 - val_loss: 0.8189 - val_mse: 0.8189 - val_mae: 0.7204\n",
      "Epoch 47/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9352 - mse: 0.9352 - mae: 0.7667 - val_loss: 0.8199 - val_mse: 0.8199 - val_mae: 0.7208\n",
      "Epoch 48/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9353 - mse: 0.9353 - mae: 0.7668 - val_loss: 0.8206 - val_mse: 0.8206 - val_mae: 0.7211\n",
      "Epoch 49/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9352 - mse: 0.9352 - mae: 0.7667 - val_loss: 0.8194 - val_mse: 0.8194 - val_mae: 0.7206\n",
      "Epoch 50/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9350 - mse: 0.9350 - mae: 0.7666 - val_loss: 0.8186 - val_mse: 0.8186 - val_mae: 0.7203\n",
      "Epoch 51/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - 80s 1s/step - loss: 0.9357 - mse: 0.9357 - mae: 0.7669 - val_loss: 0.8195 - val_mse: 0.8195 - val_mae: 0.7206\n",
      "Epoch 52/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9350 - mse: 0.9350 - mae: 0.7666 - val_loss: 0.8193 - val_mse: 0.8193 - val_mae: 0.7206\n",
      "Epoch 53/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9346 - mse: 0.9346 - mae: 0.7664 - val_loss: 0.8182 - val_mse: 0.8182 - val_mae: 0.7201\n",
      "Epoch 54/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9345 - mse: 0.9345 - mae: 0.7664 - val_loss: 0.8184 - val_mse: 0.8184 - val_mae: 0.7202\n",
      "Epoch 55/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9342 - mse: 0.9342 - mae: 0.7663 - val_loss: 0.8189 - val_mse: 0.8189 - val_mae: 0.7204\n",
      "Epoch 56/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9342 - mse: 0.9342 - mae: 0.7663 - val_loss: 0.8183 - val_mse: 0.8183 - val_mae: 0.7201\n",
      "Epoch 57/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9344 - mse: 0.9344 - mae: 0.7664 - val_loss: 0.8202 - val_mse: 0.8202 - val_mae: 0.7210\n",
      "Epoch 58/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9340 - mse: 0.9340 - mae: 0.7662 - val_loss: 0.8189 - val_mse: 0.8189 - val_mae: 0.7204\n",
      "Epoch 59/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9340 - mse: 0.9340 - mae: 0.7662 - val_loss: 0.8180 - val_mse: 0.8180 - val_mae: 0.7200\n",
      "Epoch 60/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9343 - mse: 0.9343 - mae: 0.7663 - val_loss: 0.8185 - val_mse: 0.8185 - val_mae: 0.7202\n",
      "Epoch 61/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9342 - mse: 0.9342 - mae: 0.7663 - val_loss: 0.8174 - val_mse: 0.8174 - val_mae: 0.7198\n",
      "Epoch 62/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9343 - mse: 0.9343 - mae: 0.7664 - val_loss: 0.8181 - val_mse: 0.8181 - val_mae: 0.7200\n",
      "Epoch 63/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9339 - mse: 0.9339 - mae: 0.7661 - val_loss: 0.8178 - val_mse: 0.8178 - val_mae: 0.7199\n",
      "Epoch 64/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9337 - mse: 0.9337 - mae: 0.7661 - val_loss: 0.8170 - val_mse: 0.8170 - val_mae: 0.7195\n",
      "Epoch 65/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9339 - mse: 0.9339 - mae: 0.7662 - val_loss: 0.8196 - val_mse: 0.8196 - val_mae: 0.7207\n",
      "Epoch 66/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9337 - mse: 0.9337 - mae: 0.7661 - val_loss: 0.8175 - val_mse: 0.8175 - val_mae: 0.7198\n",
      "Epoch 67/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9337 - mse: 0.9337 - mae: 0.7661 - val_loss: 0.8183 - val_mse: 0.8183 - val_mae: 0.7202\n",
      "Epoch 68/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9338 - mse: 0.9338 - mae: 0.7661 - val_loss: 0.8171 - val_mse: 0.8171 - val_mae: 0.7196\n",
      "Epoch 69/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9336 - mse: 0.9336 - mae: 0.7660 - val_loss: 0.8179 - val_mse: 0.8179 - val_mae: 0.7200\n",
      "Epoch 70/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9336 - mse: 0.9336 - mae: 0.7661 - val_loss: 0.8172 - val_mse: 0.8172 - val_mae: 0.7197\n",
      "Epoch 71/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9333 - mse: 0.9333 - mae: 0.7659 - val_loss: 0.8172 - val_mse: 0.8172 - val_mae: 0.7197\n",
      "Epoch 72/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9334 - mse: 0.9334 - mae: 0.7660 - val_loss: 0.8169 - val_mse: 0.8169 - val_mae: 0.7195\n",
      "Epoch 73/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9334 - mse: 0.9334 - mae: 0.7659 - val_loss: 0.8177 - val_mse: 0.8177 - val_mae: 0.7199\n",
      "Epoch 74/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9352 - mse: 0.9352 - mae: 0.7667 - val_loss: 0.8179 - val_mse: 0.8179 - val_mae: 0.7200\n",
      "Epoch 75/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9334 - mse: 0.9334 - mae: 0.7660 - val_loss: 0.8178 - val_mse: 0.8178 - val_mae: 0.7199\n",
      "Epoch 76/200\n",
      "75/75 [==============================] - 79s 1s/step - loss: 0.9336 - mse: 0.9336 - mae: 0.7660 - val_loss: 0.8168 - val_mse: 0.8168 - val_mae: 0.7195\n",
      "Epoch 77/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9333 - mse: 0.9333 - mae: 0.7659 - val_loss: 0.8168 - val_mse: 0.8168 - val_mae: 0.7195\n",
      "Epoch 78/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9336 - mse: 0.9336 - mae: 0.7660 - val_loss: 0.8168 - val_mse: 0.8168 - val_mae: 0.7194\n",
      "Epoch 79/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9333 - mse: 0.9333 - mae: 0.7659 - val_loss: 0.8166 - val_mse: 0.8166 - val_mae: 0.7194\n",
      "Epoch 80/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9335 - mse: 0.9335 - mae: 0.7660 - val_loss: 0.8176 - val_mse: 0.8176 - val_mae: 0.7198\n",
      "Epoch 81/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9332 - mse: 0.9332 - mae: 0.7659 - val_loss: 0.8165 - val_mse: 0.8165 - val_mae: 0.7193\n",
      "Epoch 82/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9333 - mse: 0.9333 - mae: 0.7659 - val_loss: 0.8167 - val_mse: 0.8167 - val_mae: 0.7194\n",
      "Epoch 83/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9331 - mse: 0.9331 - mae: 0.7658 - val_loss: 0.8163 - val_mse: 0.8163 - val_mae: 0.7192\n",
      "Epoch 84/200\n",
      "75/75 [==============================] - 79s 1s/step - loss: 0.9332 - mse: 0.9332 - mae: 0.7659 - val_loss: 0.8163 - val_mse: 0.8163 - val_mae: 0.7192\n",
      "Epoch 85/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9330 - mse: 0.9330 - mae: 0.7658 - val_loss: 0.8172 - val_mse: 0.8172 - val_mae: 0.7196\n",
      "Epoch 86/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9331 - mse: 0.9331 - mae: 0.7658 - val_loss: 0.8171 - val_mse: 0.8171 - val_mae: 0.7196\n",
      "Epoch 87/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9329 - mse: 0.9329 - mae: 0.7657 - val_loss: 0.8170 - val_mse: 0.8170 - val_mae: 0.7196\n",
      "Epoch 88/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9335 - mse: 0.9335 - mae: 0.7660 - val_loss: 0.8165 - val_mse: 0.8165 - val_mae: 0.7193\n",
      "Epoch 89/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9330 - mse: 0.9330 - mae: 0.7658 - val_loss: 0.8171 - val_mse: 0.8171 - val_mae: 0.7196\n",
      "Epoch 90/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9328 - mse: 0.9328 - mae: 0.7657 - val_loss: 0.8163 - val_mse: 0.8163 - val_mae: 0.7192\n",
      "Epoch 91/200\n",
      "75/75 [==============================] - 79s 1s/step - loss: 0.9336 - mse: 0.9336 - mae: 0.7660 - val_loss: 0.8168 - val_mse: 0.8168 - val_mae: 0.7195\n",
      "Epoch 92/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9329 - mse: 0.9329 - mae: 0.7657 - val_loss: 0.8165 - val_mse: 0.8165 - val_mae: 0.7193\n",
      "Epoch 93/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9331 - mse: 0.9331 - mae: 0.7658 - val_loss: 0.8185 - val_mse: 0.8185 - val_mae: 0.7202\n",
      "Epoch 94/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9330 - mse: 0.9330 - mae: 0.7658 - val_loss: 0.8166 - val_mse: 0.8166 - val_mae: 0.7194\n",
      "Epoch 95/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9329 - mse: 0.9329 - mae: 0.7657 - val_loss: 0.8168 - val_mse: 0.8168 - val_mae: 0.7195\n",
      "Epoch 96/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9329 - mse: 0.9329 - mae: 0.7657 - val_loss: 0.8164 - val_mse: 0.8164 - val_mae: 0.7193\n",
      "Epoch 97/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9327 - mse: 0.9327 - mae: 0.7657 - val_loss: 0.8178 - val_mse: 0.8178 - val_mae: 0.7199\n",
      "Epoch 98/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9329 - mse: 0.9329 - mae: 0.7657 - val_loss: 0.8163 - val_mse: 0.8163 - val_mae: 0.7193\n",
      "Epoch 99/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9328 - mse: 0.9328 - mae: 0.7657 - val_loss: 0.8171 - val_mse: 0.8171 - val_mae: 0.7196\n",
      "Epoch 100/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9328 - mse: 0.9328 - mae: 0.7657 - val_loss: 0.8164 - val_mse: 0.8164 - val_mae: 0.7193\n",
      "\n",
      "Epoch 00100: ReduceLROnPlateau reducing learning rate to 0.00019999999494757503.\n",
      "Epoch 101/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - 80s 1s/step - loss: 0.9322 - mse: 0.9322 - mae: 0.7654 - val_loss: 0.8156 - val_mse: 0.8156 - val_mae: 0.7189\n",
      "Epoch 102/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9319 - mse: 0.9319 - mae: 0.7653 - val_loss: 0.8155 - val_mse: 0.8155 - val_mae: 0.7189\n",
      "Epoch 103/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9320 - mse: 0.9320 - mae: 0.7654 - val_loss: 0.8156 - val_mse: 0.8156 - val_mae: 0.7190\n",
      "Epoch 104/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9320 - mse: 0.9320 - mae: 0.7653 - val_loss: 0.8159 - val_mse: 0.8159 - val_mae: 0.7191\n",
      "Epoch 105/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9319 - mse: 0.9319 - mae: 0.7653 - val_loss: 0.8155 - val_mse: 0.8155 - val_mae: 0.7189\n",
      "Epoch 106/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9320 - mse: 0.9320 - mae: 0.7653 - val_loss: 0.8158 - val_mse: 0.8158 - val_mae: 0.7190\n",
      "Epoch 107/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9321 - mse: 0.9321 - mae: 0.7654 - val_loss: 0.8154 - val_mse: 0.8154 - val_mae: 0.7189\n",
      "Epoch 108/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9319 - mse: 0.9319 - mae: 0.7653 - val_loss: 0.8158 - val_mse: 0.8158 - val_mae: 0.7190\n",
      "Epoch 109/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9320 - mse: 0.9320 - mae: 0.7654 - val_loss: 0.8153 - val_mse: 0.8153 - val_mae: 0.7188\n",
      "Epoch 110/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9319 - mse: 0.9319 - mae: 0.7653 - val_loss: 0.8162 - val_mse: 0.8162 - val_mae: 0.7192\n",
      "Epoch 111/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9319 - mse: 0.9319 - mae: 0.7653 - val_loss: 0.8155 - val_mse: 0.8155 - val_mae: 0.7189\n",
      "Epoch 112/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9318 - mse: 0.9318 - mae: 0.7653 - val_loss: 0.8155 - val_mse: 0.8155 - val_mae: 0.7189\n",
      "Epoch 113/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9322 - mse: 0.9322 - mae: 0.7654 - val_loss: 0.8156 - val_mse: 0.8156 - val_mae: 0.7189\n",
      "Epoch 114/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9318 - mse: 0.9318 - mae: 0.7653 - val_loss: 0.8154 - val_mse: 0.8154 - val_mae: 0.7189\n",
      "Epoch 115/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9320 - mse: 0.9320 - mae: 0.7653 - val_loss: 0.8153 - val_mse: 0.8153 - val_mae: 0.7188\n",
      "Epoch 116/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9318 - mse: 0.9318 - mae: 0.7652 - val_loss: 0.8158 - val_mse: 0.8158 - val_mae: 0.7190\n",
      "Epoch 117/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9319 - mse: 0.9319 - mae: 0.7653 - val_loss: 0.8155 - val_mse: 0.8155 - val_mae: 0.7189\n",
      "Epoch 118/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9320 - mse: 0.9320 - mae: 0.7654 - val_loss: 0.8159 - val_mse: 0.8159 - val_mae: 0.7191\n",
      "Epoch 119/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9318 - mse: 0.9318 - mae: 0.7653 - val_loss: 0.8154 - val_mse: 0.8154 - val_mae: 0.7188\n",
      "Epoch 120/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9321 - mse: 0.9321 - mae: 0.7654 - val_loss: 0.8157 - val_mse: 0.8157 - val_mae: 0.7190\n",
      "Epoch 121/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9318 - mse: 0.9318 - mae: 0.7653 - val_loss: 0.8160 - val_mse: 0.8160 - val_mae: 0.7191\n",
      "Epoch 122/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9319 - mse: 0.9319 - mae: 0.7653 - val_loss: 0.8156 - val_mse: 0.8156 - val_mae: 0.7190\n",
      "Epoch 123/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9319 - mse: 0.9319 - mae: 0.7653 - val_loss: 0.8152 - val_mse: 0.8152 - val_mae: 0.7188\n",
      "Epoch 124/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9319 - mse: 0.9319 - mae: 0.7653 - val_loss: 0.8155 - val_mse: 0.8155 - val_mae: 0.7189\n",
      "Epoch 125/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9319 - mse: 0.9319 - mae: 0.7653 - val_loss: 0.8152 - val_mse: 0.8152 - val_mae: 0.7188\n",
      "Epoch 126/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9318 - mse: 0.9318 - mae: 0.7653 - val_loss: 0.8152 - val_mse: 0.8152 - val_mae: 0.7188\n",
      "Epoch 127/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9318 - mse: 0.9318 - mae: 0.7653 - val_loss: 0.8153 - val_mse: 0.8153 - val_mae: 0.7188\n",
      "Epoch 128/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9320 - mse: 0.9320 - mae: 0.7653 - val_loss: 0.8153 - val_mse: 0.8153 - val_mae: 0.7189\n",
      "Epoch 129/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9315 - mse: 0.9315 - mae: 0.7651 - val_loss: 0.8153 - val_mse: 0.8153 - val_mae: 0.7188\n",
      "Epoch 130/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9317 - mse: 0.9317 - mae: 0.7652 - val_loss: 0.8155 - val_mse: 0.8155 - val_mae: 0.7189\n",
      "Epoch 131/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9318 - mse: 0.9318 - mae: 0.7653 - val_loss: 0.8157 - val_mse: 0.8157 - val_mae: 0.7190\n",
      "Epoch 132/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9319 - mse: 0.9319 - mae: 0.7653 - val_loss: 0.8155 - val_mse: 0.8155 - val_mae: 0.7189\n",
      "Epoch 133/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9315 - mse: 0.9315 - mae: 0.7651 - val_loss: 0.8149 - val_mse: 0.8149 - val_mae: 0.7187\n",
      "Epoch 134/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9317 - mse: 0.9317 - mae: 0.7652 - val_loss: 0.8150 - val_mse: 0.8150 - val_mae: 0.7187\n",
      "Epoch 135/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9314 - mse: 0.9314 - mae: 0.7651 - val_loss: 0.8151 - val_mse: 0.8151 - val_mae: 0.7187\n",
      "Epoch 136/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9317 - mse: 0.9317 - mae: 0.7652 - val_loss: 0.8161 - val_mse: 0.8161 - val_mae: 0.7192\n",
      "Epoch 137/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9317 - mse: 0.9317 - mae: 0.7652 - val_loss: 0.8151 - val_mse: 0.8151 - val_mae: 0.7187\n",
      "Epoch 138/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9314 - mse: 0.9314 - mae: 0.7651 - val_loss: 0.8158 - val_mse: 0.8158 - val_mae: 0.7190\n",
      "Epoch 139/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9319 - mse: 0.9319 - mae: 0.7653 - val_loss: 0.8155 - val_mse: 0.8155 - val_mae: 0.7189\n",
      "Epoch 140/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9315 - mse: 0.9315 - mae: 0.7652 - val_loss: 0.8151 - val_mse: 0.8151 - val_mae: 0.7187\n",
      "Epoch 141/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9317 - mse: 0.9317 - mae: 0.7652 - val_loss: 0.8150 - val_mse: 0.8150 - val_mae: 0.7187\n",
      "Epoch 142/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9315 - mse: 0.9315 - mae: 0.7651 - val_loss: 0.8161 - val_mse: 0.8161 - val_mae: 0.7192\n",
      "Epoch 143/200\n",
      "75/75 [==============================] - 79s 1s/step - loss: 0.9313 - mse: 0.9313 - mae: 0.7650 - val_loss: 0.8157 - val_mse: 0.8157 - val_mae: 0.7190\n",
      "\n",
      "Epoch 00143: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-05.\n",
      "Epoch 144/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9313 - mse: 0.9313 - mae: 0.7650 - val_loss: 0.8151 - val_mse: 0.8151 - val_mae: 0.7187\n",
      "Epoch 145/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9312 - mse: 0.9312 - mae: 0.7650 - val_loss: 0.8150 - val_mse: 0.8150 - val_mae: 0.7187\n",
      "Epoch 146/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9312 - mse: 0.9312 - mae: 0.7650 - val_loss: 0.8146 - val_mse: 0.8146 - val_mae: 0.7185\n",
      "Epoch 147/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9313 - mse: 0.9313 - mae: 0.7651 - val_loss: 0.8150 - val_mse: 0.8150 - val_mae: 0.7187\n",
      "Epoch 148/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9311 - mse: 0.9311 - mae: 0.7649 - val_loss: 0.8148 - val_mse: 0.8148 - val_mae: 0.7186\n",
      "Epoch 149/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9311 - mse: 0.9311 - mae: 0.7650 - val_loss: 0.8150 - val_mse: 0.8150 - val_mae: 0.7187\n",
      "Epoch 150/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - 80s 1s/step - loss: 0.9311 - mse: 0.9311 - mae: 0.7650 - val_loss: 0.8147 - val_mse: 0.8147 - val_mae: 0.7186\n",
      "Epoch 151/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9313 - mse: 0.9313 - mae: 0.7650 - val_loss: 0.8150 - val_mse: 0.8150 - val_mae: 0.7187\n",
      "Epoch 152/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9311 - mse: 0.9311 - mae: 0.7650 - val_loss: 0.8149 - val_mse: 0.8149 - val_mae: 0.7186\n",
      "Epoch 153/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9310 - mse: 0.9310 - mae: 0.7649 - val_loss: 0.8148 - val_mse: 0.8148 - val_mae: 0.7186\n",
      "Epoch 154/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9311 - mse: 0.9311 - mae: 0.7649 - val_loss: 0.8155 - val_mse: 0.8155 - val_mae: 0.7189\n",
      "Epoch 155/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9311 - mse: 0.9311 - mae: 0.7649 - val_loss: 0.8146 - val_mse: 0.8146 - val_mae: 0.7185\n",
      "Epoch 156/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9309 - mse: 0.9309 - mae: 0.7649 - val_loss: 0.8151 - val_mse: 0.8151 - val_mae: 0.7187\n",
      "Epoch 157/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9313 - mse: 0.9313 - mae: 0.7650 - val_loss: 0.8149 - val_mse: 0.8149 - val_mae: 0.7186\n",
      "Epoch 158/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9311 - mse: 0.9311 - mae: 0.7650 - val_loss: 0.8149 - val_mse: 0.8149 - val_mae: 0.7186\n",
      "Epoch 159/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9310 - mse: 0.9310 - mae: 0.7649 - val_loss: 0.8148 - val_mse: 0.8148 - val_mae: 0.7186\n",
      "Epoch 160/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9313 - mse: 0.9313 - mae: 0.7650 - val_loss: 0.8148 - val_mse: 0.8148 - val_mae: 0.7186\n",
      "Epoch 161/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9312 - mse: 0.9312 - mae: 0.7650 - val_loss: 0.8150 - val_mse: 0.8150 - val_mae: 0.7187\n",
      "Epoch 162/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9309 - mse: 0.9309 - mae: 0.7648 - val_loss: 0.8148 - val_mse: 0.8148 - val_mae: 0.7186\n",
      "Epoch 163/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9311 - mse: 0.9311 - mae: 0.7650 - val_loss: 0.8151 - val_mse: 0.8151 - val_mae: 0.7187\n",
      "Epoch 164/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9311 - mse: 0.9311 - mae: 0.7650 - val_loss: 0.8148 - val_mse: 0.8148 - val_mae: 0.7186\n",
      "Epoch 165/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9310 - mse: 0.9310 - mae: 0.7649 - val_loss: 0.8150 - val_mse: 0.8150 - val_mae: 0.7187\n",
      "\n",
      "Epoch 00165: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "Epoch 166/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9308 - mse: 0.9308 - mae: 0.7648 - val_loss: 0.8145 - val_mse: 0.8145 - val_mae: 0.7185\n",
      "Epoch 167/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9307 - mse: 0.9307 - mae: 0.7648 - val_loss: 0.8147 - val_mse: 0.8147 - val_mae: 0.7185\n",
      "Epoch 168/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9309 - mse: 0.9309 - mae: 0.7649 - val_loss: 0.8147 - val_mse: 0.8147 - val_mae: 0.7186\n",
      "Epoch 169/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9308 - mse: 0.9308 - mae: 0.7649 - val_loss: 0.8146 - val_mse: 0.8146 - val_mae: 0.7185\n",
      "Epoch 170/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9309 - mse: 0.9309 - mae: 0.7649 - val_loss: 0.8146 - val_mse: 0.8146 - val_mae: 0.7185\n",
      "Epoch 171/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9308 - mse: 0.9308 - mae: 0.7648 - val_loss: 0.8147 - val_mse: 0.8147 - val_mae: 0.7186\n",
      "Epoch 172/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9307 - mse: 0.9307 - mae: 0.7648 - val_loss: 0.8146 - val_mse: 0.8146 - val_mae: 0.7185\n",
      "Epoch 173/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9307 - mse: 0.9307 - mae: 0.7648 - val_loss: 0.8149 - val_mse: 0.8149 - val_mae: 0.7186\n",
      "Epoch 174/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9308 - mse: 0.9308 - mae: 0.7648 - val_loss: 0.8146 - val_mse: 0.8146 - val_mae: 0.7185\n",
      "Epoch 175/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9309 - mse: 0.9309 - mae: 0.7649 - val_loss: 0.8147 - val_mse: 0.8147 - val_mae: 0.7186\n",
      "Epoch 176/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9307 - mse: 0.9307 - mae: 0.7648 - val_loss: 0.8147 - val_mse: 0.8147 - val_mae: 0.7185\n",
      "\n",
      "Epoch 00176: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "Epoch 177/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9306 - mse: 0.9306 - mae: 0.7647 - val_loss: 0.8147 - val_mse: 0.8147 - val_mae: 0.7186\n",
      "Epoch 178/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9305 - mse: 0.9305 - mae: 0.7647 - val_loss: 0.8147 - val_mse: 0.8147 - val_mae: 0.7186\n",
      "Epoch 179/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9306 - mse: 0.9306 - mae: 0.7648 - val_loss: 0.8146 - val_mse: 0.8146 - val_mae: 0.7185\n",
      "Epoch 180/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9308 - mse: 0.9308 - mae: 0.7648 - val_loss: 0.8146 - val_mse: 0.8146 - val_mae: 0.7185\n",
      "Epoch 181/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9308 - mse: 0.9308 - mae: 0.7648 - val_loss: 0.8147 - val_mse: 0.8147 - val_mae: 0.7185\n",
      "Epoch 182/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9307 - mse: 0.9307 - mae: 0.7648 - val_loss: 0.8146 - val_mse: 0.8146 - val_mae: 0.7185\n",
      "Epoch 183/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9307 - mse: 0.9307 - mae: 0.7648 - val_loss: 0.8145 - val_mse: 0.8145 - val_mae: 0.7185\n",
      "Epoch 184/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9307 - mse: 0.9307 - mae: 0.7648 - val_loss: 0.8145 - val_mse: 0.8145 - val_mae: 0.7185\n",
      "Epoch 185/200\n",
      "75/75 [==============================] - 79s 1s/step - loss: 0.9309 - mse: 0.9309 - mae: 0.7649 - val_loss: 0.8147 - val_mse: 0.8147 - val_mae: 0.7186\n",
      "Epoch 186/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9306 - mse: 0.9306 - mae: 0.7648 - val_loss: 0.8146 - val_mse: 0.8146 - val_mae: 0.7185\n",
      "Epoch 187/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9307 - mse: 0.9307 - mae: 0.7648 - val_loss: 0.8147 - val_mse: 0.8147 - val_mae: 0.7185\n",
      "Epoch 188/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9305 - mse: 0.9305 - mae: 0.7647 - val_loss: 0.8147 - val_mse: 0.8147 - val_mae: 0.7185\n",
      "Epoch 189/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9308 - mse: 0.9308 - mae: 0.7649 - val_loss: 0.8147 - val_mse: 0.8147 - val_mae: 0.7186\n",
      "Epoch 190/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9306 - mse: 0.9306 - mae: 0.7647 - val_loss: 0.8145 - val_mse: 0.8145 - val_mae: 0.7185\n",
      "Epoch 191/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9308 - mse: 0.9308 - mae: 0.7649 - val_loss: 0.8145 - val_mse: 0.8145 - val_mae: 0.7185\n",
      "Epoch 192/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9308 - mse: 0.9308 - mae: 0.7648 - val_loss: 0.8145 - val_mse: 0.8145 - val_mae: 0.7185\n",
      "Epoch 193/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9306 - mse: 0.9306 - mae: 0.7648 - val_loss: 0.8144 - val_mse: 0.8144 - val_mae: 0.7184\n",
      "Epoch 194/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9305 - mse: 0.9305 - mae: 0.7647 - val_loss: 0.8146 - val_mse: 0.8146 - val_mae: 0.7185\n",
      "Epoch 195/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9306 - mse: 0.9306 - mae: 0.7648 - val_loss: 0.8145 - val_mse: 0.8145 - val_mae: 0.7185\n",
      "Epoch 196/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9305 - mse: 0.9305 - mae: 0.7647 - val_loss: 0.8146 - val_mse: 0.8146 - val_mae: 0.7185\n",
      "Epoch 197/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9306 - mse: 0.9306 - mae: 0.7648 - val_loss: 0.8146 - val_mse: 0.8146 - val_mae: 0.7185\n",
      "Epoch 198/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9306 - mse: 0.9306 - mae: 0.7647 - val_loss: 0.8145 - val_mse: 0.8145 - val_mae: 0.7185\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 199/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9307 - mse: 0.9307 - mae: 0.7648 - val_loss: 0.8146 - val_mse: 0.8146 - val_mae: 0.7185\n",
      "Epoch 200/200\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.9305 - mse: 0.9305 - mae: 0.7647 - val_loss: 0.8146 - val_mse: 0.8146 - val_mae: 0.7185\n",
      "\n",
      "Loading network weights from 'weights_best.h5'.\n"
     ]
    }
   ],
   "source": [
    "history = model.train(X, Y, (X_val, Y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['mse', 'loss', 'val_mse', 'mae', 'val_loss', 'val_mae', 'lr'])\n"
     ]
    }
   ],
   "source": [
    "print(history.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.figure(figsize=(16,5))\n",
    "plot_history(history, 'loss', 'val_loss');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can export the tensorflow model and use it with the CSBDeep Fiji-Plugin\n",
    "# model.export_TF()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
